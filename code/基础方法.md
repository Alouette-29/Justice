# 模型方法



## 任务设计

虚假诉讼在判决案件中比例小，类型复杂。  为了提高模型泛化能力，本文采用了自监督预训练和类案匹配的方法进行虚假诉讼识别。 

本文采用了2021年民间借贷纠纷案例的全集，经过分析筛选后，共有88000万条案件文书。 其中虚假诉讼约有1万余条。 

将标有虚假诉讼的案件10000条和随机抽取的15000条非虚假诉讼的案件构造成一个类别比例均衡的测试数据集。 并将模型在这个数据集上的识别准确率作为模型的判别标准。 其余数据作为自监督训练用数据。 

对测试数据集的划分有三种方式： few-shot , one-shot, division 。  few-shot切分出少量数据给模型学习。 one-shot只选择一对虚假诉讼和非虚假诉讼的案件作为引导。 division划分出10%的数据训练classifier。 

本文探索性地尝试了使用各种预训练自然语言处理模型来表征法律案件的相似度。 采用text-encoder+classfier的模型结构。 

部署方面，使用全部的测试数据集来训练classifier，以期望覆盖大部分的虚假诉讼类型，并获得更好的泛化能力。 

## 基于sentence_transformer （baseline)

用通用语料库上训练的sentence_transformer作为text-encoder，并使用多层感知机作为分类器。 

本部分在原始的文本编码器基础上，尝试增加分类器的参数量，得到一组原始的baseline的数据。 

| 模型          | Parameter                 | 20epoch测试准确率 | 40epoch测试准确率 |
| ------------- | ------------------------- | ----------------- | ----------------- |
| Single Linear | 384*2                     | 0.8278            | 0.8398            |
| Double Linear | 384*192 +192\*2           | 0.8606            | 0.8755            |
| MLP           | 384\*384+384\*384 +384\*2 | 0.8621            | 0.8606            |



## OURS: LawCaseformer :  Case-level-Lawsuit-Feature-Encoder

为了利用大规模的法律文本数据，我们利用掩码语言模型将通用语料预训练模型特化为法律领域的语言预训练模型，并增加特征提取层将不同长度的法律文本特征进行对齐，最后得到每个案件的情节输入。 

### TSADE 预训练 

[[2104.06979\] TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning (arxiv.org)](https://arxiv.org/abs/2104.06979)

本文选用相对于mask-language-model更加高效的 transformer-based-auto-denoising-encoder结构作为无监督的预训练任务。

然后通过同样的输出层对模型进行分类。 

| 模型                             | 参数量          | 20epoch测试准确率 | 40epoch |
| -------------------------------- | --------------- | ----------------- | ------- |
| TBADE 500iter+single linear      | 768*2           | 0.8991            |         |
| TBADE 500iter+Double Linear      | 384*192 +192\*2 | 0.9050            |         |
| TBADE 500iter+Double Half Linear | 384*192 +192\*2 | 0.9065            |         |



## 基于lawformer

lawformer是基于大规模的刑法数据集的transformer预训练模型。 同样经过特征提取得到案件相似度之后，加上分类器在数据集上输出准确率。 

我预期： 由于刑法和民法之间仍然存在差异，因此lawformer的效果应该不会超过我们的law-bert。 如果超过了，我们就说，我们在少量数据集和个人PC上仍然得到了competitve 的效果。 

|      |      | 20epoch测试准确率 |
| ---- | ---- | ----------------- |
|      |      |                   |
|      |      |                   |
|      |      |                   |



## CLIP判别法!

![CLIP-like-model](%E5%9F%BA%E7%A1%80%E6%96%B9%E6%B3%95/CLIP-like-model-16785348304091.png)

借鉴CLIP分类器的思想，打破原本模型只能对是否是虚假诉讼进行分类的局限，进一步提高类别的广度。 采用相似度计算的方式，判断一个虚假诉讼案件所属的子类别。

### 构造数据集

将一个案件的事实段和判决段分别拆开，然后交叉组合，得到虚假的和真实的案例的组成的数据集。 

### 训练过程

训练任务是判断一个案件事实和案件判决之间是否一致。 损失函数是交叉熵误差。

JudgeEncoder和FactEncoder是预训练的语言处理模型。 

得到FactEncoder和JudgeEncoder模型。 

### 测试过程

用FactEncoder对事实描述进行编码，得到对事实的特征向量。 然后从数据库中挑选出典型的虚假诉讼判决，输出匹配程度作为判断是否是虚假诉讼的依据。 输入一系列案件的判决，来找出与输入案件最相似的案件。 

### 模型优点

避免了单调的相似度计算

分类器更加灵活，不需要人工分类

也算是一种创新了模型架构

而且具有可解释性（我们可以隐式的给出 虚假诉讼案件的类别） 

| 方法 | 准确率 |      |
| ---- | ------ | ---- |
|      |        |      |
|      |        |      |
|      |        |      |



## DPR-zpt

DPR模型是在类案匹配的数据集上进行微调训练过的bert模型，我们推测它具有更好的提取、表征法律文书信息的能力。在含24221条数据的训练集上利用DPR编码进行二分类任务，训练3轮后loss降至0.4271385073661804，并在含有1498条数据的测试集上进行测试，达到了0.8425的准确率。在构建训练任务时仅采用一层全连接层即达到这样的效果，可证明DPR对此类问题由很好的表征能力。