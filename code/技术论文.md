# LawCaseformer :  Case-level-Lawsuit-Feature-Encoder

## Todo-list 之后删除 

- moco 主要是负责构造数据集和contrastive learning 的 ，我们要改代码放到我们的任务上
- lawformer复现，代码已经写好了，就差去跑了（得用机房） 
- DPR复现 20 epoch 40 epoch （得用机房） 
- 把main函数的代码改的适应dpr结构，然后用同一个数据集划分来评价准确度。  改好了

窦老师，我现在构造了一个比例比较均衡的数据集模拟初步筛选之后的情况。 这个数据集有10000条虚假诉讼和15000千条非虚假诉讼。 我们分别在通用语料上的预训练模型， 经过 民间借贷的文书预训练过模型，和张配天师兄给我们的DPR模型上跑过二分类问题。 初步来看，经过同样的分类头之后，我们的微调的模型比其他两个表现稍微好一点。  

但是我测试发现，在原始数据比例下，模型表现就比较差了。 为了解决长尾分布的问题，我现在有两个思路， 一个是参考Decoupling Representation and Classifier for Long-Tailed Recognition,把表征和分类分开，就是按照目前的思路继续训练；另一个是参考moco,clip 这种工作采用对比学习的方式进行训练。 做对比学习的好处是性能更好，而且可以进行对虚假诉讼继续分类。 但是从实现上来说，目前我们只能到地下机房用3080训练，可能见效会比较慢。 

请问您觉得这两种方法哪种更好，或者有别的可以解决长尾分布的问题，还是我们可以直接绕过这个问题，通过初筛来构造均衡数据集。 

## 摘要

现有的虚假诉讼识别主要基于TFIDF，显式特征抽取等机器学习方法，较少有应用到深度学习方法。 在自然语言处理领域，预训练模型已经拥有了强大的语义表示能力。 但是仍然有几个方面的问题阻碍了深度学习方法在虚假诉讼识别上的应用：1.  法律文本有大量术语，基于普通语料的预训练模型缺乏相应的表示能力。 2. 法律文本显著长于普通文本，目前常见的预训练模型都是词语级别的表征和句子级别表征，缺乏篇章级别的表征模型。 3. 虚假诉讼数据集的长尾分布让分类器的训练更加困难。  

针对问题一，本文采用TSADE自监督预训练任务在超过60万条民间借贷纠纷案件上对bert-base-chinese模型进行微调，得到法律领域民间借贷案由的特化的语言预训练模型。 

针对问题二 ,  借鉴sentence_transformer结构，本文通过将特化后的预训练模型改造为篇章级别的编码器。

针对问题三，本文提出使用解耦训练文本表征器和动量对比学习的方法，来提升长尾分布下的预测能力。

关键词： TSADE , 自监督预训练， 篇章级嵌入， 对比学习， moco 

### 英文摘要

Existed fake law suit recognition mainly based on traditional machine learning method like TFIDF, explicit feature extraction while method based on deep learning are less frequently used. In natural language processing, pretrained models has made great progress in language representation. But there are still some problem prevent deep learning from applying to fake law suit recognition. 1. there are too many professional words which hardly appear in general language materials, so those pretrained models fail to represent those text well. 2. A law suit text is significantly longer than original texts, and general pretrained models are often lack of the ability to embed long texts. 3. the long-tialed distribution of the fake law suits also prevent people from training a classifier. 

To solve the first problem, we adopt TSADE(transformer-based-auto-denoising encoder) to fine tune the bert-base-chinese model on over 600k cases to gain a specified pretrained model in law field.

To solve the second problem,  we fit our pretrained model referring to sentence_transformer architecture to gain a case-level encoder. 

To solve the third problem, we propose to introduce decoupling mechanism and Moco method to improve the performance under long-tailed dataset. 

keyword: TSADE , self-supervised learning , case-level embedding , moco , contrastive learning 



## 相关工作 Related work 

## 介绍 Introduction 

## 方法 Method 

虚假诉讼在判决案件中比例小，类型复杂。  为了提高模型泛化能力，本文采用了自监督预训练和类案匹配的方法进行虚假诉讼识别。 

本文采用了2021年民间借贷纠纷案例的全集，经过分析筛选后，共有88000万条案件文书。 其中虚假诉讼约有1万余条。 

将标有虚假诉讼的案件10000条和随机抽取的15000条非虚假诉讼的案件构造成一个类别比例均衡的测试数据集。 并将模型在这个数据集上的识别准确率作为模型的判别标准。 其余数据作为自监督训练用数据。 

对测试数据集的划分有三种方式： few-shot , one-shot, division 。  few-shot切分出少量数据给模型学习。 one-shot只选择一对虚假诉讼和非虚假诉讼的案件作为引导。 division划分出10%的数据训练classifier。 

本文探索性地尝试了使用各种预训练自然语言处理模型来表征法律案件的相似度。 采用text-encoder+classfier的模型结构。 

部署方面，使用全部的测试数据集来训练classifier，以期望覆盖大部分的虚假诉讼类型，并获得更好的泛化能力。 

为了利用大规模的法律文本数据，我们利用掩码语言模型将通用语料预训练模型特化为法律领域的语言预训练模型，并增加特征提取层将不同长度的法律文本特征进行对齐，最后得到每个案件的情节输入。 

### TSADE 预训练 

本文选用相对于mask-language-model更加高效的 transformer-based-auto-denoising-encoder结构作为无监督的预训练任务。

然后通过同样的输出层对模型进行分类。 

| 模型                               | 分类头参数量    | 20epoch测试准确率 | 40epoch测试准确率 |
| ---------------------------------- | --------------- | ----------------- | ----------------- |
| TBADE 500iter+single linear        | 768*2           | 0.8991            |                   |
| TBADE 500iter+Double Linear        | 384*384 +384\*2 | 0.9050            |                   |
| TBADE 500iter+Double Half Linear   | 384*192 +192\*2 | 0.9065            |                   |
| TBADE 30000iter+single linear      | 768*2           |                   | 0.9006            |
| TBADE 30000iter+Double Half Linear | 384*384 +384\*2 |                   | 0.9108            |
| TBADE 30000iter+Double Linear      | 384*192 +192\*2 |                   | 0.8973            |



前两个实验的对比的结论说明，基于TSADE微调的模型学习到的案件的表示效果是非常显著。 



## CLIP判别法----基于对比学习的判别模型 

![CLIP-like-model](./CLIP-like-model.png)



借鉴CLIP分类器的思想，打破原本模型只能对是否是虚假诉讼进行分类的局限，进一步提高类别的广度。 采用相似度计算的方式，判断一个虚假诉讼案件所属的子类别。

我想通过用对比学习的方式来学习表征，然后用decoupling 表征学习和分类头为两阶段的模型来解决长尾分布的问题。 

借鉴MOCO的滑动窗口匹配的问题，基于动量的



### 构造数据集

将一个案件的事实段和判决段分别拆开，然后交叉组合，得到虚假的和真实的案例的组成的数据集。 

### 训练过程

训练任务是判断一个案件事实和案件判决之间是否一致。 损失函数是交叉熵误差。

JudgeEncoder和FactEncoder是预训练的语言处理模型。 

得到FactEncoder和JudgeEncoder模型。 

### 测试过程

用FactEncoder对事实描述进行编码，得到对事实的特征向量。 然后从数据库中挑选出典型的虚假诉讼判决，输出匹配程度作为判断是否是虚假诉讼的依据。 输入一系列案件的判决，来找出与输入案件最相似的案件。 

### 模型优点

避免了单调的相似度计算

分类器更加灵活，不需要人工分类

也算是一种创新了模型架构

而且具有可解释性（我们可以隐式的给出 虚假诉讼案件的类别） 

实际上这也是一种微调任务，但是他的模型架构上看起来稍微好点？

### 模型局限

数据集的角度来说，一个案子只有一个真实的匹配的判决。 但是实际上，案情和案情之间的高度相似也是存在的。 也就是说标签数据还是有很多噪音。 

如果将案件-判决看做是一组关系R。 那么x1Ry1 = 1 ,因此关系矩阵是一个对角矩阵。 但是真实的关系矩阵，以案情相似度阈值作为判别依据的话 ，即$\{<x,y>| cosine(x,y) > \theta \}$的关系  不一定是一个对角矩阵。 

但是实际上，在cv领域常见的代理任务instance discrimination 的方法跟我们是一样的。  

| 模型 | 分类头参数量 | 20epoch测试准确率 | 40epoch测试准确率 |
| ---- | ------------ | ----------------- | ----------------- |
|      |              |                   |                   |
|      |              |                   |                   |
|      |              |                   |                   |



## Exprements 

### sentence_transformer+classifier 

用通用语料库上训练的sentence_transformer作为text-encoder，并使用多层感知机作为分类器。 

本部分在原始的文本编码器基础上，尝试增加分类器的参数量，得到一组原始的baseline的数据。 

| 模型                            | 分类头参数量              | 20epoch测试准确率 | 40epoch测试准确率 |
| ------------------------------- | ------------------------- | ----------------- | ----------------- |
| all-MiniLM-L6-v2 +Single Linear | 384*2                     | 0.8278            | 0.8398            |
| all-MiniLM-L6-v2+ Double Linear | 384*192 +192\*2           | 0.8606            | 0.8755            |
| all-MiniLM-L6-v2+ MLP           | 384\*384+384\*384 +384\*2 | 0.8621            | 0.8606            |



### lawformer+classfier 

lawformer是基于大规模的刑法数据集的transformer预训练模型。 同样经过特征提取得到案件相似度之后，加上分类器在数据集上输出准确率。 

我预期： 由于刑法和民法之间仍然存在差异，因此lawformer的效果应该不会超过我们的law-bert。 如果超过了，我们就说，我们在少量数据集和个人PC上仍然得到了competitve 的效果。 

| 方法 | 分类头参数量 | 20epoch测试准确率 |
| ---- | ------------ | ----------------- |
|      |              |                   |
|      |              |                   |
|      |              |                   |



### DPR-zpt

DPR模型是在类案匹配的数据集上进行微调训练过的bert模型，我们推测它具有更好的提取、表征法律文书信息的能力。在含24221条数据的训练集上利用DPR编码进行二分类任务，训练3轮后loss降至0.4271385073661804，并在含有1498条数据的测试集上进行测试，达到了0.8425的准确率。在构建训练任务时仅采用一层全连接层即达到这样的效果，可证明DPR对此类问题由很好的表征能力。

| 模型 | 分类头参数量 | 3epoch测试准确率 | 40epoch测试准确率 |
| ---- | ------------ | ---------------- | ----------------- |
|      |              | 0.8425           |                   |
|      |              |                  |                   |
|      |              |                  |                   |

> 训练20轮， 然后把你用的分类头描述一下

### 主要参考文献

参考文献 Decoupling representation and classifier for long-tailed data 

​				MOCO  - hekaiming 

[[2104.06979\] TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning (arxiv.org)](https://arxiv.org/abs/2104.06979)

​				CLIP -open ai 

​				sentence_transformer 

​					SIMCSE自然语言的对比学习。 这个可能也是一个参考文献。  

我只写了我这一部分的。 