# 每日进度更新

| WHY       | 完成工作                                                     | 想法/问题/思考                                               |
| --------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 2022.2.1  | 尝试中文实体识别模型，看知识表示的导入，处理地图信息         |                                                              |
| 2022.2.2  | QT+python开发可视化界面，GPT系列模型思想，跑bert-base-chinese预训练模型 | 结合实体识别，在对文书进行tokenizer的阶段，mask掉人名地名组织名； 单独对案件的涉案的人，组织进行表征 ;1· |
| 2022.2.3  | demo-> transformer_sentence / 案件空间分布热力图/ 读论文attention is all you need / 一个交互的html页面(含javascript) | 搞图谱肯定是来不及了，就用transformer/bert 了估计            |
| 2022.2.4  | 开始数据预处理，统计数据集的基本情况                         |                                                              |
| 2022.2.5  | 修改content 字段                                             |                                                              |
| 2022.2.6  | 用正则表达式删除残留的html5 ，整理之前的代码                 |                                                              |
| 2022.2.7  | 写数据预处理思路，和一个实验思路                             |                                                              |
| 2022.2.8  | 抽取了除了content字段之外有用的数据做成了一个表格            | 想做传统的机器学习的特征。 大概有1%的案例直接提到了虚假诉讼  |
| 2022.2.9  | FaceFormer                                                   |                                                              |
| 2022.2.10 | FaceFormer                                                   |                                                              |
| 2022.2.11 | 无工作                                                       |                                                              |
| 2022.2.12 | 无工作                                                       |                                                              |
| 2022.2.13 | 1. df 表的法规名称 做一个embedding 2. 搞一个聚类的模板，检验一下 横向数据 和content embedding的效果 3. 改file_reader的接口，不用npy用json √ 4. 继续改正则表达式 | 虚假诉讼的案子不够做监督数据，但是可以用来做测试数据，把虚假诉讼的部分抹掉，然后看判断准确性 。 问题： 我们基本上确定用bert做编码，但是我们怎么样不做虚假诉讼检验的时候，就确定这个编码方式效果不错呢 。 |
| 2022.2.14 |                                                              |                                                              |
|           |                                                              |                                                              |
|           |                                                              |                                                              |
|           |                                                              |                                                              |
|           |                                                              |                                                              |
|           |                                                              |                                                              |





2.2思考

考虑到时间紧迫，做知识图谱很有可能来不及，但是可以采用实体识别+tokenize的方法进行训练？ 

然后用生成模型做一些数据增强和特征提取的优化。  

language model足够强大是可以看懂代词的？ 
